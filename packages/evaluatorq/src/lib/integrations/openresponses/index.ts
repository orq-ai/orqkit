/**
 * OpenResponses types for evaluatorq.
 *
 * These types represent the OpenResponses format, an industry standard for
 * representing LLM agent interactions including messages, function calls,
 * and their outputs.
 */

// =============================================================================
// Enums
// =============================================================================

export const messageRoleEnum = {
  user: "user",
  assistant: "assistant",
  system: "system",
  developer: "developer",
} as const;

export type MessageRole =
  (typeof messageRoleEnum)[keyof typeof messageRoleEnum];

export const messageStatusEnum = {
  in_progress: "in_progress",
  completed: "completed",
  incomplete: "incomplete",
} as const;

export type MessageStatus =
  (typeof messageStatusEnum)[keyof typeof messageStatusEnum];

export const functionCallStatusEnum = {
  in_progress: "in_progress",
  completed: "completed",
  incomplete: "incomplete",
} as const;

export type FunctionCallStatus =
  (typeof functionCallStatusEnum)[keyof typeof functionCallStatusEnum];

export const functionCallOutputStatusEnumEnum = {
  in_progress: "in_progress",
  completed: "completed",
  incomplete: "incomplete",
} as const;

export type FunctionCallOutputStatusEnum =
  (typeof functionCallOutputStatusEnumEnum)[keyof typeof functionCallOutputStatusEnumEnum];

// =============================================================================
// Content Types
// =============================================================================

/**
 * A text input to the model.
 */
export interface InputTextContent {
  /** The type of the input item. Always `input_text`. */
  type: "input_text";
  /** The text input to the model. */
  text: string;
}

/**
 * A text output from the model.
 */
export interface OutputTextContent {
  /** The type of the output text. Always `output_text`. */
  type: "output_text";
  /** The text output from the model. */
  text: string;
  /** The annotations of the text output. */
  annotations: unknown[];
  /** Log probabilities for the output tokens. */
  logprobs: unknown[];
}

// =============================================================================
// Detail Types
// =============================================================================

/**
 * A breakdown of input token usage that was recorded.
 */
export interface InputTokensDetails {
  /** The number of input tokens that were served from cache. */
  cached_tokens: number;
}

/**
 * A breakdown of output token usage that was recorded.
 */
export interface OutputTokensDetails {
  /** The number of output tokens that were attributed to reasoning. */
  reasoning_tokens: number;
}

/**
 * Details about why the response was incomplete.
 */
export interface IncompleteDetails {
  /** The reason the response could not be completed. */
  reason: string;
}

// =============================================================================
// Core Types
// =============================================================================

/**
 * A function tool call that was generated by the model.
 */
export interface FunctionCall {
  /** The type of the item. Always `function_call`. */
  type: "function_call";
  /** The unique ID of the function call item. */
  id: string;
  /** The unique ID of the function tool call that was generated. */
  call_id: string;
  /** The name of the function that was called. */
  name: string;
  /** The arguments JSON string that was generated. */
  arguments: string;
  /** The status of the function call. */
  status: FunctionCallStatus;
}

/**
 * A function tool call output that was returned by the tool.
 */
export interface FunctionCallOutput {
  /** The type of the function tool call output. Always `function_call_output`. */
  type: "function_call_output";
  /** The unique ID of the function tool call output. */
  id: string;
  /** The unique ID of the function tool call generated by the model. */
  call_id: string;
  /** The output from the function call. */
  output: string;
  /** The status of the function call output. */
  status: FunctionCallOutputStatusEnum;
}

/**
 * Defines a function in your own code the model can choose to call.
 */
export interface FunctionTool {
  /** The type of the function tool. Always `function`. */
  type: "function";
  /** The name of the function to call. */
  name: string;
  /** A description of what the function does. */
  description: string | null;
  /** The parameters the function accepts, as a JSON Schema object. */
  parameters: Record<string, unknown> | null;
  /** Whether to enable strict schema adherence. */
  strict: boolean | null;
}

/**
 * A message to or from the model.
 */
export interface Message {
  /** The type of the message. Always set to `message`. */
  type: "message";
  /** The unique ID of the message. */
  id: string;
  /** The status of the message. */
  status: MessageStatus;
  /** The role of the message sender. */
  role: MessageRole;
  /** The content of the message. */
  content: Array<
    InputTextContent | OutputTextContent | Record<string, unknown>
  >;
}

/**
 * Token usage statistics that were recorded for the response.
 */
export interface Usage {
  /** The number of input tokens that were used to generate the response. */
  input_tokens: number;
  /** The number of output tokens that were generated by the model. */
  output_tokens: number;
  /** The total number of tokens that were used. */
  total_tokens: number;
  /** A breakdown of input token usage. */
  input_tokens_details: InputTokensDetails;
  /** A breakdown of output token usage. */
  output_tokens_details: OutputTokensDetails;
}

/**
 * Text format configuration.
 */
export interface TextField {
  /** The format configuration for text output. */
  format: Record<string, unknown>;
  /** The verbosity level. */
  verbosity?: string;
}

/**
 * An item representing a message, tool call, tool output, or other response element.
 */
export type ItemField = Message | FunctionCall | FunctionCallOutput;

/**
 * The complete response object in OpenResponses format.
 *
 * This represents the industry standard format for representing
 * LLM agent interactions.
 */
export interface ResponseResource {
  /** The unique ID of the response that was created. */
  id: string;
  /** The object type. Always `response`. */
  object: "response";
  /** The Unix timestamp (in seconds) for when the response was created. */
  created_at: number;
  /** The Unix timestamp for when the response was completed. */
  completed_at: number | null;
  /** The status that was set for the response. */
  status: string;
  /** Details about why the response was incomplete. */
  incomplete_details: IncompleteDetails | null;
  /** The model that generated this response. */
  model: string;
  /** The ID of the previous response in a conversation. */
  previous_response_id: string | null;
  /** System instructions provided to the model. */
  instructions: string | null;
  /** The input items provided to the model. */
  input: ItemField[];
  /** The output items that were generated by the model. */
  output: ItemField[];
  /** Error information if the response failed. */
  error: Record<string, unknown> | null;
  /** The tools that were available to the model during response generation. */
  tools: FunctionTool[];
  /** How the model should choose which tool to use. */
  tool_choice: string;
  /** How input should be truncated if it exceeds max context. */
  truncation: string;
  /** Whether the model was allowed to call multiple tools in parallel. */
  parallel_tool_calls: boolean;
  /** Text format configuration. */
  text: TextField;
  /** The nucleus sampling parameter that was used for this response. */
  top_p: number;
  /** The presence penalty that was used. */
  presence_penalty: number;
  /** The frequency penalty that was used. */
  frequency_penalty: number;
  /** The number of most likely tokens returned at each position. */
  top_logprobs: number;
  /** The sampling temperature that was used for this response. */
  temperature: number;
  /** Reasoning configuration. */
  reasoning: Record<string, unknown> | null;
  /** Token usage statistics. */
  usage: Usage | null;
  /** Maximum output tokens allowed. */
  max_output_tokens: number | null;
  /** Maximum tool calls allowed. */
  max_tool_calls: number | null;
  /** Whether this response was stored for later retrieval. */
  store: boolean;
  /** Whether this request was run in the background. */
  background: boolean;
  /** The service tier that was used for this response. */
  service_tier: string;
  /** Developer-defined metadata associated with the response. */
  metadata: Record<string, unknown>;
  /** Safety identifier for the response. */
  safety_identifier: string | null;
  /** Prompt cache key if caching was used. */
  prompt_cache_key: string | null;
}
